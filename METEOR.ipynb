{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meteor Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re as re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibility\n",
    "## Data Collection\n",
    "@Misc{acl-ocl,\n",
    "    author =       {Shaurya Rohatgi, Yanxia Qin, Benjamin Aw, Niranjana Unnithan, Min-Yen Kan},\n",
    "    title =        {The ACL OCL Corpus: advancing Open science in Computational Linguistics},\n",
    "    howpublished = {arXiv},\n",
    "    year =         {2022},\n",
    "    url =          {https://huggingface.co/datasets/ACL-OCL/ACL-OCL-Corpus}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acl_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>full_text</th>\n",
       "      <th>corpus_paper_id</th>\n",
       "      <th>pdf_hash</th>\n",
       "      <th>numcitedby</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>address</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>doi</th>\n",
       "      <th>number</th>\n",
       "      <th>volume</th>\n",
       "      <th>journal</th>\n",
       "      <th>editor</th>\n",
       "      <th>isbn</th>\n",
       "      <th>ENTRYTYPE</th>\n",
       "      <th>ID</th>\n",
       "      <th>language</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O02-2002</td>\n",
       "      <td>There is a need to measure word similarity whe...</td>\n",
       "      <td>There is a need to measure word similarity whe...</td>\n",
       "      <td>18022704</td>\n",
       "      <td>0b09178ac8d17a92f16140365363d8df88c757d0</td>\n",
       "      <td>14</td>\n",
       "      <td>https://aclanthology.org/O02-2002</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2002</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>chen-you-2002-study</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L02-1310</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8220988</td>\n",
       "      <td>8d5e31610bc82c2abc86bc20ceba684c97e66024</td>\n",
       "      <td>93</td>\n",
       "      <td>http://www.lrec-conf.org/proceedings/lrec2002/...</td>\n",
       "      <td>European Language Resources Association (ELRA)</td>\n",
       "      <td>Las Palmas, Canary Islands - Spain</td>\n",
       "      <td>2002</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>mihalcea-2002-bootstrapping</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R13-1042</td>\n",
       "      <td>Thread disentanglement is the task of separati...</td>\n",
       "      <td>Thread disentanglement is the task of separati...</td>\n",
       "      <td>16703040</td>\n",
       "      <td>3eb736b17a5acb583b9a9bd99837427753632cdb</td>\n",
       "      <td>10</td>\n",
       "      <td>https://aclanthology.org/R13-1042</td>\n",
       "      <td>INCOMA Ltd. Shoumen, BULGARIA</td>\n",
       "      <td>Hissar, Bulgaria</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>jamison-gurevych-2013-headerless</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W05-0819</td>\n",
       "      <td>In this paper, we describe a word alignment al...</td>\n",
       "      <td>In this paper, we describe a word alignment al...</td>\n",
       "      <td>1215281</td>\n",
       "      <td>b20450f67116e59d1348fc472cfc09f96e348f55</td>\n",
       "      <td>15</td>\n",
       "      <td>https://aclanthology.org/W05-0819</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>Ann Arbor, Michigan</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>aswani-gaizauskas-2005-aligning</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L02-1309</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>18078432</td>\n",
       "      <td>011e943b64a78dadc3440674419821ee080f0de3</td>\n",
       "      <td>12</td>\n",
       "      <td>http://www.lrec-conf.org/proceedings/lrec2002/...</td>\n",
       "      <td>European Language Resources Association (ELRA)</td>\n",
       "      <td>Las Palmas, Canary Islands - Spain</td>\n",
       "      <td>2002</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>suyaga-etal-2002-proposal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     acl_id                                           abstract  \\\n",
       "0  O02-2002  There is a need to measure word similarity whe...   \n",
       "1  L02-1310                                               None   \n",
       "2  R13-1042  Thread disentanglement is the task of separati...   \n",
       "3  W05-0819  In this paper, we describe a word alignment al...   \n",
       "4  L02-1309                                               None   \n",
       "\n",
       "                                           full_text  corpus_paper_id  \\\n",
       "0  There is a need to measure word similarity whe...         18022704   \n",
       "1                                               None          8220988   \n",
       "2  Thread disentanglement is the task of separati...         16703040   \n",
       "3  In this paper, we describe a word alignment al...          1215281   \n",
       "4                                               None         18078432   \n",
       "\n",
       "                                   pdf_hash  numcitedby  \\\n",
       "0  0b09178ac8d17a92f16140365363d8df88c757d0          14   \n",
       "1  8d5e31610bc82c2abc86bc20ceba684c97e66024          93   \n",
       "2  3eb736b17a5acb583b9a9bd99837427753632cdb          10   \n",
       "3  b20450f67116e59d1348fc472cfc09f96e348f55          15   \n",
       "4  011e943b64a78dadc3440674419821ee080f0de3          12   \n",
       "\n",
       "                                                 url  \\\n",
       "0                  https://aclanthology.org/O02-2002   \n",
       "1  http://www.lrec-conf.org/proceedings/lrec2002/...   \n",
       "2                  https://aclanthology.org/R13-1042   \n",
       "3                  https://aclanthology.org/W05-0819   \n",
       "4  http://www.lrec-conf.org/proceedings/lrec2002/...   \n",
       "\n",
       "                                        publisher  \\\n",
       "0                                            None   \n",
       "1  European Language Resources Association (ELRA)   \n",
       "2                   INCOMA Ltd. Shoumen, BULGARIA   \n",
       "3       Association for Computational Linguistics   \n",
       "4  European Language Resources Association (ELRA)   \n",
       "\n",
       "                              address  year  ...   doi number volume journal  \\\n",
       "0                                None  2002  ...  None   None   None    None   \n",
       "1  Las Palmas, Canary Islands - Spain  2002  ...  None   None   None    None   \n",
       "2                    Hissar, Bulgaria  2013  ...  None   None   None    None   \n",
       "3                 Ann Arbor, Michigan  2005  ...  None   None   None    None   \n",
       "4  Las Palmas, Canary Islands - Spain  2002  ...  None   None   None    None   \n",
       "\n",
       "  editor  isbn      ENTRYTYPE                                ID language  note  \n",
       "0   None  None  inproceedings               chen-you-2002-study     None  None  \n",
       "1   None  None  inproceedings       mihalcea-2002-bootstrapping     None  None  \n",
       "2   None  None  inproceedings  jamison-gurevych-2013-headerless     None  None  \n",
       "3   None  None  inproceedings   aswani-gaizauskas-2005-aligning     None  None  \n",
       "4   None  None  inproceedings         suyaga-etal-2002-proposal     None  None  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('data/acl-publication-info.74k.v2.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acl_id             73285\n",
       "abstract           67669\n",
       "full_text          67455\n",
       "corpus_paper_id    73285\n",
       "pdf_hash           72076\n",
       "numcitedby         73285\n",
       "url                73285\n",
       "publisher          63166\n",
       "address            66093\n",
       "year               73285\n",
       "month              65962\n",
       "booktitle          71244\n",
       "author             72618\n",
       "title              73285\n",
       "pages              59478\n",
       "doi                29678\n",
       "number              1474\n",
       "volume              1840\n",
       "journal             2037\n",
       "editor                13\n",
       "isbn                1370\n",
       "ENTRYTYPE          73285\n",
       "ID                 73285\n",
       "language            3020\n",
       "note                 197\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paper_ident        67455\n",
       "paper_text         67455\n",
       "paper_url          67455\n",
       "paper_publisher    57851\n",
       "paper_address      60454\n",
       "paper_year         67455\n",
       "paper_month        60301\n",
       "paper_booktitle    65440\n",
       "paper_author       66888\n",
       "paper_title        67455\n",
       "paper_pages        57195\n",
       "paper_doi          29456\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_renamed = df.rename(columns={\"acl_id\": \"paper_ident\",\n",
    "                   \"url\": \"paper_url\",\n",
    "                   \"publisher\": \"paper_publisher\",\n",
    "                   \"address\": \"paper_address\",\n",
    "                   \"year\": \"paper_year\",\n",
    "                   \"month\": \"paper_month\",\n",
    "                   \"booktitle\": \"paper_booktitle\",\n",
    "                   \"author\": \"paper_author\",\n",
    "                   \"title\": \"paper_title\",\n",
    "                   \"pages\": \"paper_pages\",\n",
    "                   \"full_text\": \"paper_text\",\n",
    "                   \"doi\": \"paper_doi\"\n",
    "                   })\n",
    "\n",
    "df_cleaned = df_renamed.drop(columns=[\"abstract\", \"corpus_paper_id\", \"pdf_hash\", \n",
    "                              \"numcitedby\", \"number\", \"volume\", \"journal\", \n",
    "                              \"editor\", \"isbn\", \"ENTRYTYPE\",\"ID\", \"language\", \"note\"])\n",
    "\n",
    "df_full = df_cleaned.dropna(subset=[\"paper_text\"])\n",
    "df_full.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## METEOR Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1613"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meteor_prelim = df_full.copy()\n",
    "df_meteor_prelim[\"paper_meteor_prelim\"] = df_meteor_prelim[\"paper_text\"].str.contains(\" meteor \", case=False)\n",
    "df_meteor_prelim['paper_meteor_prelim'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "df_meteor_prelim.to_csv(\"out.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Review\n",
    "### METEOR Parameters\n",
    "Parameters according to https://www.cs.cmu.edu/~alavie/METEOR/README.html\n",
    "\n",
    "-l language                     Fully supported: en cz de es fr ar\n",
    "                                Supported with language-independent parameters:\n",
    "                                  da fi hu it nl no pt ro ru se \n",
    "                                  \n",
    "-t task                         One of: rank util adq hter li tune\n",
    "                                  util implies -ch\n",
    "\n",
    "-p 'alpha beta gamma delta'     Custom parameters (overrides default)\n",
    "\n",
    "-m 'module1 module2 ...'        Specify modules (overrides default)\n",
    "                                  Any of: exact stem synonym paraphrase\n",
    "\n",
    "-w 'weight1 weight2 ...'        Specify module weights (overrides default)\n",
    "\n",
    "-r refCount                     Number of references (plaintext only)\n",
    "\n",
    "-x beamSize                     (default 40)\n",
    "\n",
    "-s wordListDirectory            (if not default for language)\n",
    "\n",
    "-d synonymDirectory             (if not default for language)\n",
    "\n",
    "-a paraphraseFile               (if not default for language)\n",
    "\n",
    "-f filePrefix                   Prefix for output files (default 'meteor')\n",
    "\n",
    "-q                              Quiet: Segment scores to stderr, final to stdout,\n",
    "                                  no additional output (plaintext only)\n",
    "\n",
    "-ch                             Character-based precision and recall\n",
    "\n",
    "-norm                           Tokenize / normalize punctuation and lowercase\n",
    "                                  (Recommended unless scoring raw output with\n",
    "                                   pretokenized references)\n",
    "\n",
    "-lower                          Lowercase only (not required if -norm specified)\n",
    "\n",
    "-noPunct                        Do not consider punctuation when scoring\n",
    "                                  (Not recommended unless special case)\n",
    "\n",
    "-sgml                           Input is in SGML format\n",
    "\n",
    "-mira                           Input is in MIRA format\n",
    "                                  (Use '-' for test and reference files)\n",
    "\n",
    "-vOut                           Output verbose scores (P / R / frag / score)\n",
    "\n",
    "-ssOut                          Output sufficient statistics instead of scores\n",
    "\n",
    "-writeAlignments                Output alignments annotated with Meteor scores\n",
    "                                  (written to <prefix>-align.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parameters(text):\n",
    "    pattern = r\"((?: -[a-z123](?: [a-z0-9.]{1,4})?){2,})\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    return matches[0] if matches else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params = df_meteor_prelim.copy()\n",
    "df_params[\"paper_params\"] = df_params.apply(lambda row: extract_parameters(row['paper_text']) if row['paper_meteor_prelim'] else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_params['paper_params'].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_ident</th>\n",
       "      <th>paper_text</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>paper_publisher</th>\n",
       "      <th>paper_address</th>\n",
       "      <th>paper_year</th>\n",
       "      <th>paper_month</th>\n",
       "      <th>paper_booktitle</th>\n",
       "      <th>paper_author</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_pages</th>\n",
       "      <th>paper_doi</th>\n",
       "      <th>paper_meteor_prelim</th>\n",
       "      <th>paper_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>W15-3016</td>\n",
       "      <td>This paper describes LIMSI's submissions to th...</td>\n",
       "      <td>https://aclanthology.org/W15-3016</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>Lisbon, Portugal</td>\n",
       "      <td>2015</td>\n",
       "      <td>September</td>\n",
       "      <td>Proceedings of the Tenth Workshop on Statistic...</td>\n",
       "      <td>Marie, Benjamin  and\\nAllauzen, Alexandre  and...</td>\n",
       "      <td>{LIMSI}@{WMT}{'}15 : Translation Task</td>\n",
       "      <td>145--151</td>\n",
       "      <td>10.18653/v1/W15-3016</td>\n",
       "      <td>True</td>\n",
       "      <td>-o -v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>2016.amta-researchers.7</td>\n",
       "      <td>Domain adaptation is a major challenge when ap...</td>\n",
       "      <td>https://aclanthology.org/2016.amta-researchers.7</td>\n",
       "      <td>The Association for Machine Translation in the...</td>\n",
       "      <td>Austin, TX, USA</td>\n",
       "      <td>2016</td>\n",
       "      <td>October 28 - November 1</td>\n",
       "      <td>Conferences of the Association for Machine Tra...</td>\n",
       "      <td>Imamura, Kenji  and\\nSumita, Eiichiro</td>\n",
       "      <td>Multi-domain Adaptation for Statistical Machin...</td>\n",
       "      <td>79--92</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>-3 to -2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3287</th>\n",
       "      <td>C18-1102</td>\n",
       "      <td>In this work, we aim at developing an unsuperv...</td>\n",
       "      <td>https://aclanthology.org/C18-1102</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>Santa Fe, New Mexico, USA</td>\n",
       "      <td>2018</td>\n",
       "      <td>August</td>\n",
       "      <td>Proceedings of the 27th International Conferen...</td>\n",
       "      <td>Nayeem, Mir Tafseer  and\\nFuad, Tanvir Ahmed  ...</td>\n",
       "      <td>Abstractive Unsupervised Multi-Document Summar...</td>\n",
       "      <td>1191--1204</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>-n 2 -m -u -c 95 -x -r 1000 -f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17137</th>\n",
       "      <td>J13-4009</td>\n",
       "      <td>In this article we investigate statistical mac...</td>\n",
       "      <td>https://aclanthology.org/J13-4009</td>\n",
       "      <td>MIT Press</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>2013</td>\n",
       "      <td>December</td>\n",
       "      <td>None</td>\n",
       "      <td>Stymne, Sara  and\\nCancedda, Nicola  and\\nAhre...</td>\n",
       "      <td>Generation of Compound Words in Statistical Ma...</td>\n",
       "      <td>1067--1108</td>\n",
       "      <td>10.1162/COLI_a_00162</td>\n",
       "      <td>True</td>\n",
       "      <td>-s or -e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19988</th>\n",
       "      <td>W14-3336</td>\n",
       "      <td>This paper presents the results of the WMT14 M...</td>\n",
       "      <td>https://aclanthology.org/W14-3336</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>Baltimore, Maryland, USA</td>\n",
       "      <td>2014</td>\n",
       "      <td>June</td>\n",
       "      <td>Proceedings of the Ninth Workshop on Statistic...</td>\n",
       "      <td>Mach{\\'a}{\\v{c}}ek, Matou{\\v{s}}  and\\nBojar, ...</td>\n",
       "      <td>Results of the {WMT}14 Metrics Shared Task</td>\n",
       "      <td>293--301</td>\n",
       "      <td>10.3115/v1/W14-3336</td>\n",
       "      <td>True</td>\n",
       "      <td>-1 -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20220</th>\n",
       "      <td>W18-6450</td>\n",
       "      <td>This paper presents the results of the WMT18 M...</td>\n",
       "      <td>https://aclanthology.org/W18-6450</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>Belgium, Brussels</td>\n",
       "      <td>2018</td>\n",
       "      <td>October</td>\n",
       "      <td>Proceedings of the Third Conference on Machine...</td>\n",
       "      <td>Ma, Qingsong  and\\nBojar, Ond{\\v{r}}ej  and\\nG...</td>\n",
       "      <td>Results of the {WMT}18 Metrics Shared Task: Bo...</td>\n",
       "      <td>671--688</td>\n",
       "      <td>10.18653/v1/W18-6450</td>\n",
       "      <td>True</td>\n",
       "      <td>-1 -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22214</th>\n",
       "      <td>2011.eamt-1.10</td>\n",
       "      <td>The increasing use of eXtensible Markup Langua...</td>\n",
       "      <td>https://aclanthology.org/2011.eamt-1.10</td>\n",
       "      <td>European Association for Machine Translation</td>\n",
       "      <td>Leuven, Belgium</td>\n",
       "      <td>2011</td>\n",
       "      <td>May 30{--}31</td>\n",
       "      <td>Proceedings of the 15th Annual conference of t...</td>\n",
       "      <td>Tezcan, Arda  and\\nVandeghinste, Vincent</td>\n",
       "      <td>{SMT}-{CAT} integration in a Technical Domain:...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>-t -d 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28824</th>\n",
       "      <td>W14-3315</td>\n",
       "      <td>We describe the CMU systems submitted to the 2...</td>\n",
       "      <td>https://aclanthology.org/W14-3315</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>Baltimore, Maryland, USA</td>\n",
       "      <td>2014</td>\n",
       "      <td>June</td>\n",
       "      <td>Proceedings of the Ninth Workshop on Statistic...</td>\n",
       "      <td>Matthews, Austin  and\\nAmmar, Waleed  and\\nBha...</td>\n",
       "      <td>The {CMU} Machine Translation Systems at {WMT}...</td>\n",
       "      <td>142--149</td>\n",
       "      <td>10.3115/v1/W14-3315</td>\n",
       "      <td>True</td>\n",
       "      <td>-s or -e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66515</th>\n",
       "      <td>2008.eamt-1.25</td>\n",
       "      <td>We investigated the effects of processing Swed...</td>\n",
       "      <td>https://aclanthology.org/2008.eamt-1.25</td>\n",
       "      <td>European Association for Machine Translation</td>\n",
       "      <td>Hamburg, Germany</td>\n",
       "      <td>2008</td>\n",
       "      <td>September 22-23</td>\n",
       "      <td>Proceedings of the 12th Annual conference of t...</td>\n",
       "      <td>Stymne, Sara  and\\nHolmquist, Maria</td>\n",
       "      <td>Processing of {S}wedish compounds for phrase-b...</td>\n",
       "      <td>182--191</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>-e -a pojk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   paper_ident  \\\n",
       "1245                  W15-3016   \n",
       "3200   2016.amta-researchers.7   \n",
       "3287                  C18-1102   \n",
       "17137                 J13-4009   \n",
       "19988                 W14-3336   \n",
       "20220                 W18-6450   \n",
       "22214           2011.eamt-1.10   \n",
       "28824                 W14-3315   \n",
       "66515           2008.eamt-1.25   \n",
       "\n",
       "                                              paper_text  \\\n",
       "1245   This paper describes LIMSI's submissions to th...   \n",
       "3200   Domain adaptation is a major challenge when ap...   \n",
       "3287   In this work, we aim at developing an unsuperv...   \n",
       "17137  In this article we investigate statistical mac...   \n",
       "19988  This paper presents the results of the WMT14 M...   \n",
       "20220  This paper presents the results of the WMT18 M...   \n",
       "22214  The increasing use of eXtensible Markup Langua...   \n",
       "28824  We describe the CMU systems submitted to the 2...   \n",
       "66515  We investigated the effects of processing Swed...   \n",
       "\n",
       "                                              paper_url  \\\n",
       "1245                  https://aclanthology.org/W15-3016   \n",
       "3200   https://aclanthology.org/2016.amta-researchers.7   \n",
       "3287                  https://aclanthology.org/C18-1102   \n",
       "17137                 https://aclanthology.org/J13-4009   \n",
       "19988                 https://aclanthology.org/W14-3336   \n",
       "20220                 https://aclanthology.org/W18-6450   \n",
       "22214           https://aclanthology.org/2011.eamt-1.10   \n",
       "28824                 https://aclanthology.org/W14-3315   \n",
       "66515           https://aclanthology.org/2008.eamt-1.25   \n",
       "\n",
       "                                         paper_publisher  \\\n",
       "1245           Association for Computational Linguistics   \n",
       "3200   The Association for Machine Translation in the...   \n",
       "3287           Association for Computational Linguistics   \n",
       "17137                                          MIT Press   \n",
       "19988          Association for Computational Linguistics   \n",
       "20220          Association for Computational Linguistics   \n",
       "22214       European Association for Machine Translation   \n",
       "28824          Association for Computational Linguistics   \n",
       "66515       European Association for Machine Translation   \n",
       "\n",
       "                   paper_address paper_year              paper_month  \\\n",
       "1245            Lisbon, Portugal       2015                September   \n",
       "3200             Austin, TX, USA       2016  October 28 - November 1   \n",
       "3287   Santa Fe, New Mexico, USA       2018                   August   \n",
       "17137              Cambridge, MA       2013                 December   \n",
       "19988   Baltimore, Maryland, USA       2014                     June   \n",
       "20220          Belgium, Brussels       2018                  October   \n",
       "22214            Leuven, Belgium       2011             May 30{--}31   \n",
       "28824   Baltimore, Maryland, USA       2014                     June   \n",
       "66515           Hamburg, Germany       2008          September 22-23   \n",
       "\n",
       "                                         paper_booktitle  \\\n",
       "1245   Proceedings of the Tenth Workshop on Statistic...   \n",
       "3200   Conferences of the Association for Machine Tra...   \n",
       "3287   Proceedings of the 27th International Conferen...   \n",
       "17137                                               None   \n",
       "19988  Proceedings of the Ninth Workshop on Statistic...   \n",
       "20220  Proceedings of the Third Conference on Machine...   \n",
       "22214  Proceedings of the 15th Annual conference of t...   \n",
       "28824  Proceedings of the Ninth Workshop on Statistic...   \n",
       "66515  Proceedings of the 12th Annual conference of t...   \n",
       "\n",
       "                                            paper_author  \\\n",
       "1245   Marie, Benjamin  and\\nAllauzen, Alexandre  and...   \n",
       "3200               Imamura, Kenji  and\\nSumita, Eiichiro   \n",
       "3287   Nayeem, Mir Tafseer  and\\nFuad, Tanvir Ahmed  ...   \n",
       "17137  Stymne, Sara  and\\nCancedda, Nicola  and\\nAhre...   \n",
       "19988  Mach{\\'a}{\\v{c}}ek, Matou{\\v{s}}  and\\nBojar, ...   \n",
       "20220  Ma, Qingsong  and\\nBojar, Ond{\\v{r}}ej  and\\nG...   \n",
       "22214           Tezcan, Arda  and\\nVandeghinste, Vincent   \n",
       "28824  Matthews, Austin  and\\nAmmar, Waleed  and\\nBha...   \n",
       "66515                Stymne, Sara  and\\nHolmquist, Maria   \n",
       "\n",
       "                                             paper_title paper_pages  \\\n",
       "1245               {LIMSI}@{WMT}{'}15 : Translation Task    145--151   \n",
       "3200   Multi-domain Adaptation for Statistical Machin...      79--92   \n",
       "3287   Abstractive Unsupervised Multi-Document Summar...  1191--1204   \n",
       "17137  Generation of Compound Words in Statistical Ma...  1067--1108   \n",
       "19988         Results of the {WMT}14 Metrics Shared Task    293--301   \n",
       "20220  Results of the {WMT}18 Metrics Shared Task: Bo...    671--688   \n",
       "22214  {SMT}-{CAT} integration in a Technical Domain:...        None   \n",
       "28824  The {CMU} Machine Translation Systems at {WMT}...    142--149   \n",
       "66515  Processing of {S}wedish compounds for phrase-b...    182--191   \n",
       "\n",
       "                  paper_doi  paper_meteor_prelim  \\\n",
       "1245   10.18653/v1/W15-3016                 True   \n",
       "3200                   None                 True   \n",
       "3287                   None                 True   \n",
       "17137  10.1162/COLI_a_00162                 True   \n",
       "19988   10.3115/v1/W14-3336                 True   \n",
       "20220  10.18653/v1/W18-6450                 True   \n",
       "22214                  None                 True   \n",
       "28824   10.3115/v1/W14-3315                 True   \n",
       "66515                  None                 True   \n",
       "\n",
       "                          paper_params  \n",
       "1245                             -o -v  \n",
       "3200                          -3 to -2  \n",
       "3287    -n 2 -m -u -c 95 -x -r 1000 -f  \n",
       "17137                         -s or -e  \n",
       "19988                            -1 -1  \n",
       "20220                            -1 -1  \n",
       "22214                          -t -d 0  \n",
       "28824                         -s or -e  \n",
       "66515                       -e -a pojk  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_params[df_params['paper_params'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METEOR Protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Language: -l language\n",
    "    - Use settings for specified language. Lang can be either the language name or two letter code. See the supported language list.\n",
    "    - Fully supported: en cz de es fr ar\n",
    "    - Supported with language-independent parameters: fi hu it nl no pt ro ru se tr\n",
    "    \n",
    "- Task: -t task\n",
    "    - Use a different pre-defined set of parameters for scoring (currently limited to English):\n",
    "        - rank: parameters tuned to human rankings from WMT09 and WMT10\n",
    "        - adq: parameters tuned to adequacy scores from NIST Open MT 2009\n",
    "        - hter: parameters tuned to HTER scores from GALE P2 and P3\n",
    "        - li: language-independent parameters\n",
    "    - One of: rank util adq hter li tune (util implies -ch)\n",
    "\n",
    "- Modules: -m 'module1 module2 ...'\n",
    "    - Set modules manually. Options are: exact stem synonym paraphrase. See supported languages. Module string should be quoted. \n",
    "\n",
    "- Normalize: -norm\n",
    "    - Tokenize and lowercases input lines, normalize punctuation to improve scoring accuracy. This option is highly recommended unless scoring raw system output against pretokenized references. \n",
    "\n",
    "- Lowercase: -lower\n",
    "    - Lowercase input lines (not required if -norm also specified). This is most commonly used scoring cased, tokenized outputs with pretokenized references. \n",
    "\n",
    "- Ignore Punctuation: -noPunct\n",
    "    - If specified, punctuation symbols will be removed before scoring. This is generally not recommended as parameters are tuned with punctuation included. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_protocol = {\n",
    "    'rank': r'\\b(?:rank|ranking|WMT09|WMT10)\\b',\n",
    "    'adq': r'\\b(?:adq|adequacy|NIST Open MT 2009)\\b',\n",
    "    'hter': r'\\b(?:hter|HUMAN-targeted translation edit rate|GALE P2|GALE P3)\\b',\n",
    "    'li': r'\\b(?:li|language[- ]independent)\\b',\n",
    "    'tune': r'\\b(?:tune|tuning|parameter optimization)\\b',\n",
    "    'modules': r'\\b(?:-m\\s+(?:exact|stem|synonym|paraphrase)|module|exact|stem|synonym|paraphrase)\\b',\n",
    "    'normalize': r'\\b(?:-norm|normalize|normalization|tokenize\\s+and\\s+lowercase|normalize\\s+punctuation)\\b',\n",
    "    'lowercase': r'\\b(?:-lower|lowercase|lowercasing|casing)\\b',\n",
    "    'ignore_punctuation': r'\\b(?:-noPunct|no\\s+Punctuation|ignore\\s+punctuation|remove\\s+punctuation)\\b'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_terms_near_meteor(text, regex_dict):\n",
    "    results = []\n",
    "    for term, pattern in regex_dict.items():\n",
    "        # Find all occurrences of 'meteor' (case insensitive)\n",
    "        for match in re.finditer(r'meteor', text, re.IGNORECASE):\n",
    "            start, end = match.start(), match.end()\n",
    "            # Define a 500-character window around 'meteor'\n",
    "            window_start, window_end = max(0, start - 500), min(len(text), end + 500)\n",
    "            # Search for the term within this window\n",
    "            if re.search(pattern, text[window_start:window_end], re.IGNORECASE):\n",
    "                results.append(term)\n",
    "    return list(set(results))  # Return unique terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_protocol=df_params.copy()\n",
    "df_protocol['paper_protocol'] = df_protocol[df_protocol['paper_meteor_prelim'] == True]['paper_text'].apply(lambda x: search_terms_near_meteor(x, regex_protocol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              paper_text  paper_meteor_prelim  \\\n",
      "256    This paper presents the LIG participation to t...                 True   \n",
      "333    This paper presents a new hypothesis alignment...                 True   \n",
      "421    Research on statistical machine translation ha...                 True   \n",
      "454    Graph-to-text generation aims to generate flue...                 True   \n",
      "559    This paper describes a computational linguisti...                 True   \n",
      "...                                                  ...                  ...   \n",
      "72910  Machine translation systems are vulnerable to ...                 True   \n",
      "73011  Current evaluation metrics for language modeli...                 True   \n",
      "73094  Medical terminologies resources and standards ...                 True   \n",
      "73204  Letter-like communications (such as email) are...                 True   \n",
      "73251  Codeswitching is an omnipresent phe nomenon in...                 True   \n",
      "\n",
      "              paper_protocol  \n",
      "256                   [tune]  \n",
      "333    [modules, tune, rank]  \n",
      "421                   [tune]  \n",
      "454                   [tune]  \n",
      "559                    [adq]  \n",
      "...                      ...  \n",
      "72910            [adq, rank]  \n",
      "73011              [modules]  \n",
      "73094              [modules]  \n",
      "73204                 [rank]  \n",
      "73251        [li, normalize]  \n",
      "\n",
      "[789 rows x 3 columns]\n",
      "paper_protocol\n",
      "[modules]                          183\n",
      "[tune]                             131\n",
      "[rank]                              91\n",
      "[adq]                               50\n",
      "[li]                                46\n",
      "                                  ... \n",
      "[tune, normalize, rank]              1\n",
      "[hter, rank]                         1\n",
      "[lowercase, modules, normalize]      1\n",
      "[adq, modules, normalize]            1\n",
      "[hter, adq, rank]                    1\n",
      "Name: count, Length: 66, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the relevant columns\n",
    "filtered_df_protocol = df_protocol[(df_protocol['paper_meteor_prelim'] == True) & (df_protocol['paper_protocol'].astype(bool))]\n",
    "\n",
    "# Display the filtered rows\n",
    "print(filtered_df_protocol[['paper_text', 'paper_meteor_prelim', 'paper_protocol']])\n",
    "print(filtered_df_protocol[\"paper_protocol\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variants\n",
    "- Character-based -ch\n",
    "    - Calculate character-based precision and recall. Alignment is still word and phrase-level. Fragmentation penalty is still word and phrase-level. \n",
    "\n",
    "- Ignore Punctuation: -noPunct\n",
    "    - If specified, punctuation symbols will be removed before scoring. This is generally not recommended as parameters are tuned with punctuation included.\n",
    "\n",
    "- Verbose Output: -vOut\n",
    "    - Output verbose scores (Precision, Recall, Fragmentation, Score) in place of regular scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_variants = {\n",
    "    'character_based': r'\\b(?:-ch|character[- ]based|calculate\\s+character[- ]based\\s+precision\\s+and\\s+recall)\\b',\n",
    "    'ignore_punctuation': r'\\b(?:-noPunct|no\\s+punctuation|ignore\\s+punctuation|remove\\s+punctuation)\\b',\n",
    "    'verbose_output': r'\\b(?:-vOut|verbose\\s+output|output\\s+verbose\\s+scores)\\b'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variants=df_protocol.copy()\n",
    "df_variants['paper_variants'] = df_variants[df_variants['paper_meteor_prelim'] == True]['paper_text'].apply(lambda x: search_terms_near_meteor(x, regex_variants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              paper_text  paper_meteor_prelim  \\\n",
      "2089   In this paper, we demonstrate that accurate ma...                 True   \n",
      "2912   In this paper, we present the Moses-based infr...                 True   \n",
      "15971  In recent years, machine learning models have ...                 True   \n",
      "26670  Question generation (QG) attempts to solve the...                 True   \n",
      "37679  Multiword Expressions (MWEs) are a frequently ...                 True   \n",
      "46148  This paper reports the results of the first ex...                 True   \n",
      "52543  This paper proposes a new automatic machine tr...                 True   \n",
      "58489  Dialogue summarization is receiving increasing...                 True   \n",
      "60815  Reliably evaluating Machine Translation (MT) t...                 True   \n",
      "66845  We propose WMD O , a metric based on distance ...                 True   \n",
      "72673  We present CHARCUT, a character-based machine ...                 True   \n",
      "\n",
      "          paper_variants  \n",
      "2089   [character_based]  \n",
      "2912   [character_based]  \n",
      "15971  [character_based]  \n",
      "26670  [character_based]  \n",
      "37679  [character_based]  \n",
      "46148  [character_based]  \n",
      "52543  [character_based]  \n",
      "58489  [character_based]  \n",
      "60815  [character_based]  \n",
      "66845  [character_based]  \n",
      "72673  [character_based]  \n",
      "paper_variants\n",
      "[]                   1602\n",
      "[character_based]      11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the relevant columns\n",
    "filtered_df_variants = df_variants[(df_variants['paper_meteor_prelim'] == True) & (df_variants['paper_variants'].astype(bool))]\n",
    "\n",
    "# Display the filtered rows\n",
    "print(filtered_df_variants[['paper_text', 'paper_meteor_prelim', 'paper_variants']])\n",
    "print(df_variants['paper_variants'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METEOR packages\n",
    "- Original METEOR (Java): https://www.cs.cmu.edu/~alavie/METEOR/\n",
    "- MS/meteor https://github.com/tylin/coco-caption/tree/3a9afb2682141a03e1cdc02b0df6770d2c884f6f/pycocoevalcap/meteor\n",
    "    - python wrapper for Java\n",
    "- pymeteor https://github.com/zembrodt/pymeteor\n",
    "    - python implementation\n",
    "- NLTK: https://github.com/nltk/nltk/blob/develop/nltk/translate/meteor_score.py\n",
    "    - python implementation\n",
    "- GenerationEval https://github.com/WebNLG/GenerationEval/blob/master/eval.py\n",
    "    - NLTK\n",
    "- EvaluateMetric https://huggingface.co/spaces/evaluate-metric/meteor\n",
    "    - NLTK\n",
    "- Fairseq https://github.com/facebookresearch/fairseq/blob/main/fairseq/scoring/meteor.py\n",
    "    - NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_meteor_versions = {\n",
    "    'Meteor_1.5': r'Meteor\\s+Universal.*?Denkowski.*?Lavie.*?EACL.*?2014',\n",
    "    'Meteor_1.3': r'Meteor\\s+1\\.3.*?Denkowski.*?Lavie.*?EMNLP.*?2011',\n",
    "    'Meteor_NEXT': r'METEOR-NEXT.*?Denkowski.*?Lavie.*?ACL.*?2010',\n",
    "    'Meteor_Phrase_Level': r'Meteor.*?Phrase\\s+Level.*?NAACL/HLT.*?2010',\n",
    "    'Meteor_MT_2010': r'METEOR.*?Machine\\s+Translation.*?Machine\\s+Translation.*?2010',\n",
    "    'Meteor_MBleu_MTer': r'METEOR.*?M-BLEU.*?M-TER.*?ACL.*?2008',\n",
    "    'Meteor_Automatic_MT_2007': r'METEOR.*?Automatic.*?MT\\s+Evaluation.*?ACL.*?2007',\n",
    "    'Meteor_Automatic_MT_2005': r'METEOR.*?Automatic.*?MT\\s+Evaluation.*?ACL.*?2005',\n",
    "    \"coco\":r'coco-cap',\n",
    "    \"pymeteor\": r'pymeteor|zembrodt',   \n",
    "    \"generationeval\": r'generationeval|webnlg',\n",
    "    \"evaluatemetric\": r'evaluatemetric|evaluate-metric',    \n",
    "    \"fairseq\": r'fairseq' \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_regex_pattern(text, regex_dict):\n",
    "    results = []\n",
    "    for term, pattern in regex_dict.items():\n",
    "        # Search for the pattern in the entire text\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            results.append(term)\n",
    "    return list(set(results))  # Return unique terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_packages = df_variants.copy()\n",
    "# Applying the function to the DataFrame\n",
    "df_packages['paper_packages'] = df_packages[df_packages['paper_meteor_prelim'] == True]['paper_text'].apply(lambda x: search_for_regex_pattern(x, regex_meteor_versions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Meteor_MT_2010']\n",
      "['generationeval']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_Automatic_MT_2005']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010', 'Meteor_Automatic_MT_2007', 'Meteor_Automatic_MT_2005', 'Meteor_NEXT']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_Automatic_MT_2005']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['generationeval', 'fairseq']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['Meteor_Automatic_MT_2007', 'Meteor_Automatic_MT_2005']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010', 'fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['Meteor_Automatic_MT_2005']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010', 'coco']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_Automatic_MT_2005']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_Automatic_MT_2007', 'Meteor_Automatic_MT_2005']\n",
      "['Meteor_Automatic_MT_2007', 'Meteor_Automatic_MT_2005']\n",
      "['fairseq']\n",
      "['generationeval']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['fairseq']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['coco']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['coco']\n",
      "['fairseq']\n",
      "['Meteor_Automatic_MT_2005']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['generationeval', 'fairseq']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['Meteor_MT_2010']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['coco']\n",
      "['generationeval']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010', 'generationeval', 'fairseq']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['Meteor_Automatic_MT_2007', 'Meteor_Automatic_MT_2005']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010', 'Meteor_Automatic_MT_2007']\n",
      "['generationeval']\n",
      "['Meteor_MBleu_MTer']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010', 'fairseq']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['generationeval']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['coco']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['generationeval']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['generationeval']\n",
      "['coco', 'fairseq']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['generationeval']\n",
      "['Meteor_MT_2010']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['generationeval']\n",
      "['Meteor_MT_2010']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010', 'Meteor_Automatic_MT_2007', 'Meteor_Automatic_MT_2005']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['fairseq']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['generationeval']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['coco']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['fairseq']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_Automatic_MT_2007', 'Meteor_Automatic_MT_2005']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['coco']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['fairseq']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010']\n",
      "['generationeval']\n",
      "['generationeval']\n",
      "['fairseq']\n",
      "['generationeval']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['generationeval']\n",
      "['Meteor_MT_2010', 'generationeval']\n",
      "['coco']\n",
      "['Meteor_MT_2010']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n",
      "['Meteor_MT_2010', 'Meteor_Automatic_MT_2007', 'Meteor_Automatic_MT_2005']\n",
      "['generationeval']\n",
      "['Meteor_MT_2010']\n",
      "['fairseq']\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df_packages[(df_packages['paper_meteor_prelim'] == True) & (df_packages['paper_packages'].astype(bool))]\n",
    "\n",
    "# Displaying the results\n",
    "meteor_packages_str = '\\n'.join(filtered_df['paper_packages'].astype(str))\n",
    "\n",
    "# Print the string\n",
    "print(meteor_packages_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paper_packages\n",
       "[Meteor_MT_2010]                                                                     102\n",
       "[generationeval]                                                                      57\n",
       "[fairseq]                                                                             47\n",
       "[coco]                                                                                 7\n",
       "[Meteor_Automatic_MT_2005]                                                             5\n",
       "[Meteor_Automatic_MT_2007, Meteor_Automatic_MT_2005]                                   5\n",
       "[generationeval, fairseq]                                                              2\n",
       "[Meteor_MT_2010, fairseq]                                                              2\n",
       "[Meteor_MT_2010, Meteor_Automatic_MT_2007, Meteor_Automatic_MT_2005]                   2\n",
       "[Meteor_MT_2010, Meteor_Automatic_MT_2007, Meteor_Automatic_MT_2005, Meteor_NEXT]      1\n",
       "[Meteor_MT_2010, coco]                                                                 1\n",
       "[Meteor_MT_2010, generationeval, fairseq]                                              1\n",
       "[Meteor_MT_2010, Meteor_Automatic_MT_2007]                                             1\n",
       "[Meteor_MBleu_MTer]                                                                    1\n",
       "[coco, fairseq]                                                                        1\n",
       "[Meteor_MT_2010, generationeval]                                                       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df[\"paper_packages\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_packages = {\n",
    "    \"meteor_something\" : r'\\b(?:\\w+meteor|meteor[\\w.]+)\\b',\n",
    "    \"nltk\": r'nltk',\n",
    "    \"nltk_old\": r'nltk\\s*(==)?\\s*(([0-2]\\.\\d+\\.\\d+)|3\\.[0-3]\\.\\d+|3\\.4\\.0)',\n",
    "    \"nltk_341\": r'nltk\\s*(==)?\\s*(3\\.4\\.[1-9]|3\\.4\\.[1-9]\\d+|3\\.[5]\\.\\d+|3\\.6\\.[0-2])',\n",
    "    \"nltk_363\": r'nltk\\s*(==)?\\s*3\\.6\\.[3-4]',\n",
    "    \"nltk_365\": r'nltk\\s*(==)?\\s*(3\\.6\\.[5-9]|[4-9]\\.\\d+\\.\\d+|3\\.[7-9]\\.\\d+|3\\.6\\.\\d{2,})', \n",
    "    \"nltk_version\": r'nltk\\s*(\\d+\\.\\d+(?:\\.\\d+)?)?'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_regex_pattern(text, regex_dict):\n",
    "    results = []\n",
    "    for pattern in regex_dict.values():\n",
    "        # Search for the pattern in the entire text and extract matches\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        results.extend(matches)\n",
    "    return list(set(results))  # Return unique extracted patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_variants.copy()\n",
    "# Applying the function to the DataFrame\n",
    "df_temp['meteor_packages'] = df_temp[df_temp['paper_meteor_prelim'] == True]['paper_text'].apply(lambda x: extract_regex_pattern(x, regex_packages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['METEORand']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['Meteor1.5', 'METEORderived']\n",
      "['HMeteor', 'HMETEOR']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['HMETEOR']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['meteor.com']\n",
      "['', 'NLTK']\n",
      "['METEORR']\n",
      "['METEORR']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['CMeteor', 'VMeteor']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['MeteorNP']\n",
      "['HMETEOR']\n",
      "['', 'NLTK']\n",
      "['METEOR.porter', 'METEOR.wn2', 'METEOR.wn1', 'METEOR.exact']\n",
      "['', 'NLTK']\n",
      "['METEORWSD']\n",
      "['', 'NLTK']\n",
      "['tenceMeteor']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['Meteorological', 'meteorologists']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['meteoroid']\n",
      "['nltk', 'NLTK', '']\n",
      "['', 'NLTK']\n",
      "['meteorological', 'meteorologists', 'meteorologist']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['HMETEOR']\n",
      "['', 'NLTK']\n",
      "[('==', '3.4.5'), 'NLTK', 'meteors', '']\n",
      "['', 'NLTK']\n",
      "['nltk', '']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['meteorranking']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['nltk', '']\n",
      "['meteorological']\n",
      "['', 'NLTK']\n",
      "['HMETEOR']\n",
      "['nltk', '']\n",
      "['HMETEOR']\n",
      "['nltk', 'NLTK', '']\n",
      "['METEORR']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['HMETEOR']\n",
      "['nltk', 'meteor_score.html', '']\n",
      "['', 'NLTK']\n",
      "['nltk', '']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['nltk', '']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['meteors']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['Meteorbased']\n",
      "['', 'NLTK']\n",
      "['HMETEOR']\n",
      "['HMETEOR']\n",
      "['', 'NLTK']\n",
      "['', 'NLTK']\n",
      "['nltk', 'NLTK', '']\n",
      "['', 'NLTK']\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df_temp[(df_temp['paper_meteor_prelim'] == True) & (df_temp['meteor_packages'].astype(bool))]\n",
    "\n",
    "# Displaying the results\n",
    "meteor_packages_str = '\\n'.join(filtered_df['meteor_packages'].astype(str))\n",
    "\n",
    "# Print the string\n",
    "print(meteor_packages_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Review\n",
    "### Get URLs from papers\n",
    "- [ ] code_url\tURL of code repository cited in paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_url = df_packages.copy()\n",
    "\n",
    "# Assuming df_url is your DataFrame and it contains the column 'paper_text'\n",
    "# Define the regex pattern for URLs\n",
    "regex_url = r'https?://(?:www\\.)?(?:github\\.com)[^\\s)]*(?<!\\.)'\n",
    "\n",
    "# Function to extract URLs from a text\n",
    "def extract_urls(text):\n",
    "    return re.findall(regex_url, text)\n",
    "\n",
    "# Filter the DataFrame to rows where 'paper_meteor_prelim' is True, then extract URLs\n",
    "extracted_urls = df_url[df_url['paper_meteor_prelim'] == True]['paper_text'].apply(extract_urls).explode().dropna().unique().tolist()\n",
    "\n",
    "urls_df = pd.DataFrame(extracted_urls, columns=['URLs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# Function to check if a URL exists\n",
    "def url_exists(url):\n",
    "    try:\n",
    "        response = requests.head(url, allow_redirects=True, timeout=5)\n",
    "        return response.status_code == 200\n",
    "    except requests.RequestException:\n",
    "        return False\n",
    "\n",
    "# Check if each URL is active and add the result to a new column in the DataFrame\n",
    "urls_df['active'] = urls_df['URLs'].apply(url_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all rows where 'active' is False\n",
    "urls_df = urls_df[urls_df['active']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Github API to search for meteor\n",
    "- [ ] code_meteor_prelim\tDoes the code mention Meteor? Identified using GitHub API search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the necessary part of the GitHub URL for the API request\n",
    "def extract_github_repo_name(url):\n",
    "    # Splitting the URL and extracting the repository part\n",
    "    # Typical GitHub URL format: https://github.com/username/repository\n",
    "    parts = url.split('/')\n",
    "    if len(parts) > 4 and 'github.com' in parts:\n",
    "        # Extracting the username and repository name\n",
    "        return '/'.join(parts[3:5])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to the 'URLs' column\n",
    "urls_df['GitHub_Repo'] = urls_df['URLs'].apply(extract_github_repo_name)\n",
    "\n",
    "# Filtering out rows where the GitHub repository name couldn't be extracted\n",
    "urls_df = urls_df[urls_df['GitHub_Repo'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Function to search a GitHub repository for a keyword\n",
    "def search_github_repo(repo_name, keyword='meteor', token=github_token):\n",
    "    headers = {\n",
    "        'Authorization': f'token {token}',\n",
    "        'Accept': 'application/vnd.github.v3+json'\n",
    "    }\n",
    "    search_url = f'https://api.github.com/search/code?q={keyword}+repo:{repo_name}'\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['total_count']\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.json().get('message', 'No message')}\")\n",
    "        return None\n",
    "\n",
    "# Apply the search function to each GitHub repository, respecting the rate limit\n",
    "search_results = []\n",
    "for i, repo_name in enumerate(urls_df['GitHub_Repo']):\n",
    "    count = search_github_repo(repo_name)\n",
    "    search_results.append({\n",
    "        'Repository': repo_name,\n",
    "        'Meteor_Count': count\n",
    "    })\n",
    "    # Respect the rate limit\n",
    "    if i % 9 == 8:  # After every 9th request\n",
    "        time.sleep(60)\n",
    "        \n",
    "# Convert the results to a DataFrame\n",
    "search_results_df = pd.DataFrame(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the search_results_df to keep only rows where 'Meteor_Count' is greater than 0\n",
    "filtered_search_results_df = search_results_df[search_results_df['Meteor_Count'] > 0]\n",
    "filtered_search_results_df.to_csv(\"out.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Code Review\n",
    "- [ ] code_meteor\tDoes the code perform reproducible Meteor evaluation? Manual static review, subjective assessment of Rouge evaluation reproducibility.\n",
    "\n",
    "- [ ] code_packages\tList of Meteor packages found in code. Identified using manual review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "R1: Paper cites METEOR package and parameters.\n",
    "\n",
    "R2: Paper cites no-config4 METEOR package.\n",
    "\n",
    "R3: Codebase has complete METEOR evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reproducible = df_packages.copy()\n",
    "df_reproducible['reproducible'] = None  # Initialize the column with None\n",
    "condition = df_reproducible['paper_packages'].notna() & df_reproducible['paper_params'].notna()\n",
    "df_reproducible.loc[condition, 'reproducible'] = 'R1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "r1_count = df_reproducible['reproducible'].value_counts().get('R1', 0)\n",
    "\n",
    "# Print the count\n",
    "print(r1_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "- how to define code reproducibility\n",
    "- is it enough if they say they used nlgeval? YES\n",
    "- moving to github\n",
    "- how to store github access token but not publish it\n",
    "\n",
    "- go to thesis meetup?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo\n",
    "- redo search for bitbucket etc\n",
    "- merge code review with literature review\n",
    "- redo text search for packages\n",
    "\n",
    "dsd\n",
    "- how do wrappers differ? put them in buckets\n",
    "\n",
    "dsd\n",
    "- comparability of scores\n",
    "- influence of parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
